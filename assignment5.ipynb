{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "8fB67WQTP4JY"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "vE6CLTtJP4Ja"
      },
      "outputs": [],
      "source": [
        "# Define the KNN class\n",
        "class KNN:\n",
        "    def __init__(self, k=3, distance_metric='euclidean'):\n",
        "        self.k = k\n",
        "        self.distance_metric = distance_metric\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.X_train = X\n",
        "        self.y_train = y\n",
        "\n",
        "    def predict(self, X):\n",
        "        y_preds = []\n",
        "        X = np.array(X)\n",
        "        for row in X:\n",
        "            distances = self.compute_distance(row, self.X_train)\n",
        "            inds = np.argsort(distances)[:self.k]\n",
        "            k_nearest = self.y_train.iloc[inds].values\n",
        "            churn = np.mean(k_nearest)\n",
        "            y_preds.append(churn)\n",
        "\n",
        "        return np.array(y_preds)\n",
        "\n",
        "    def compute_distance(self, X1, X2):\n",
        "        # euclidean\n",
        "        if self.distance_metric == 'euclidean':\n",
        "            return np.linalg.norm(X2 - X1, axis=1)\n",
        "\n",
        "        # manhattan\n",
        "        elif self.distance_metric == 'manhattan':\n",
        "            return np.sum(np.abs(X2 - X1), axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "PwDaXmwdP4Jb"
      },
      "outputs": [],
      "source": [
        "# Define data preprocessing function\n",
        "def preprocess_data(train_path, test_path):\n",
        "    train_data = pd.read_csv(train_path)\n",
        "    test_data = pd.read_csv(test_path)\n",
        "\n",
        "    # extract only the relevant features\n",
        "    X_raw = train_data.drop(columns=['id', 'CustomerId', 'Surname', 'Exited'])\n",
        "    y = train_data['Exited']\n",
        "    X_test_raw = test_data.drop(columns=['id', 'CustomerId', 'Surname'])\n",
        "\n",
        "    # one hot encode geography and gender\n",
        "    X_raw = pd.get_dummies(X_raw)\n",
        "    X_test_raw = pd.get_dummies(X_test_raw)\n",
        "\n",
        "    # realign\n",
        "    X_test_raw = X_test_raw.reindex(columns=X_raw.columns, fill_value=0)\n",
        "\n",
        "    # standardize using z-score normalization\n",
        "    m = X_raw.mean(axis=0)\n",
        "    sd = X_raw.std(axis=0)\n",
        "    X_scaled = (X_raw - m) / sd\n",
        "    X_test_scaled = (X_test_raw - m) / sd\n",
        "\n",
        "    return X_scaled, y, X_test_scaled"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "EPrVhPzMP4Jb"
      },
      "outputs": [],
      "source": [
        "# Define cross-validation\n",
        "def cross_validate(X, y, knn, n_splits=5):\n",
        "    unique_classes, class_counts = np.unique(y, return_counts=True)\n",
        "    indices_per_class = [np.where(y == cls)[0] for cls in unique_classes]\n",
        "\n",
        "    fold_indices = [[] for _ in range(n_splits)]\n",
        "\n",
        "    for cls_indices in indices_per_class:\n",
        "        np.random.shuffle(cls_indices)\n",
        "        for i, index in enumerate(cls_indices):\n",
        "            fold_indices[i % n_splits].append(index)\n",
        "\n",
        "    scores = []\n",
        "    for i in range(n_splits):\n",
        "        val_indices = fold_indices[i]\n",
        "        train_indices = np.hstack([fold_indices[j] for j in range(n_splits) if j != i])\n",
        "\n",
        "        X_train, X_val = X.iloc[train_indices], X.iloc[val_indices]\n",
        "        y_train, y_val = y.iloc[train_indices], y.iloc[val_indices]\n",
        "\n",
        "        knn.fit(X_train, y_train)\n",
        "        y_val_pred = knn.predict(X_val)\n",
        "        score = compute_roc_auc(y_val, y_val_pred)\n",
        "        scores.append(score)\n",
        "\n",
        "    return scores\n",
        "\n",
        "def compute_roc_auc(y_true, y_pred):\n",
        "    sorted_indices = np.argsort(y_pred)[::-1]\n",
        "    sorted_y_true = y_true.iloc[sorted_indices]\n",
        "\n",
        "    tpr = np.cumsum(sorted_y_true) / sorted_y_true.sum()\n",
        "    fpr = np.cumsum(1 - sorted_y_true) / (len(sorted_y_true) - sorted_y_true.sum())\n",
        "\n",
        "    auc = np.trapz(tpr, fpr)\n",
        "    return auc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_CRFXlCHP4Jb",
        "outputId": "d4df526d-f0cd-4b70-98b0-944104c9a188"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing default model...\n",
            "Default cross-validation scores: 0.8555934286468776\n",
            "\n",
            "Evaluating k=5 and metric=euclidean...\n",
            "Cross-validation score for k=5 and metric=euclidean: 0.857772\n",
            "\n",
            "Evaluating k=5 and metric=manhattan...\n",
            "Cross-validation score for k=5 and metric=manhattan: 0.869665\n",
            "\n",
            "Evaluating k=15 and metric=euclidean...\n",
            "Cross-validation score for k=15 and metric=euclidean: 0.898402\n",
            "\n",
            "Evaluating k=15 and metric=manhattan...\n",
            "Cross-validation score for k=15 and metric=manhattan: 0.897487\n",
            "\n",
            "Evaluating k=25 and metric=euclidean...\n",
            "Cross-validation score for k=25 and metric=euclidean: 0.902697\n",
            "\n",
            "Evaluating k=25 and metric=manhattan...\n",
            "Cross-validation score for k=25 and metric=manhattan: 0.904907\n",
            "\n",
            "Evaluating k=35 and metric=euclidean...\n",
            "Cross-validation score for k=35 and metric=euclidean: 0.903270\n",
            "\n",
            "Evaluating k=35 and metric=manhattan...\n",
            "Cross-validation score for k=35 and metric=manhattan: 0.904102\n",
            "\n",
            "Evaluating k=45 and metric=euclidean...\n",
            "Cross-validation score for k=45 and metric=euclidean: 0.904842\n",
            "\n",
            "Evaluating k=45 and metric=manhattan...\n",
            "Cross-validation score for k=45 and metric=manhattan: 0.905959\n",
            "\n",
            "Evaluating k=55 and metric=euclidean...\n",
            "Cross-validation score for k=55 and metric=euclidean: 0.903091\n",
            "\n",
            "Evaluating k=55 and metric=manhattan...\n",
            "Cross-validation score for k=55 and metric=manhattan: 0.906231\n",
            "\n",
            "Evaluating k=65 and metric=euclidean...\n",
            "Cross-validation score for k=65 and metric=euclidean: 0.901208\n",
            "\n",
            "Evaluating k=65 and metric=manhattan...\n",
            "Cross-validation score for k=65 and metric=manhattan: 0.904869\n",
            "\n",
            "Evaluating k=75 and metric=euclidean...\n",
            "Cross-validation score for k=75 and metric=euclidean: 0.902212\n",
            "\n",
            "Evaluating k=75 and metric=manhattan...\n",
            "Cross-validation score for k=75 and metric=manhattan: 0.904024\n",
            "\n",
            "Evaluating k=85 and metric=euclidean...\n",
            "Cross-validation score for k=85 and metric=euclidean: 0.900242\n",
            "\n",
            "Evaluating k=85 and metric=manhattan...\n",
            "Cross-validation score for k=85 and metric=manhattan: 0.903479\n",
            "\n",
            "Evaluating k=95 and metric=euclidean...\n",
            "Cross-validation score for k=95 and metric=euclidean: 0.899657\n",
            "\n",
            "Evaluating k=95 and metric=manhattan...\n",
            "Cross-validation score for k=95 and metric=manhattan: 0.904227\n",
            "\n",
            "Evaluating k=500 and metric=euclidean...\n",
            "Cross-validation score for k=500 and metric=euclidean: 0.874776\n",
            "\n",
            "Evaluating k=500 and metric=manhattan...\n",
            "Cross-validation score for k=500 and metric=manhattan: 0.885740\n",
            "\n",
            "Best k: 55 and metric: manhattan with score: 0.9062305806632199\n"
          ]
        }
      ],
      "source": [
        "# Load and preprocess data\n",
        "X, y, X_test = preprocess_data('/content/train.csv', '/content/test.csv')\n",
        "\n",
        "# Create and evaluate model\n",
        "knn = KNN(k=5, distance_metric='euclidean')\n",
        "\n",
        "# Perform cross-validation\n",
        "print('Testing default model...')\n",
        "cv_scores = cross_validate(X, y, knn)\n",
        "print(f'Default cross-validation scores: {np.mean(cv_scores)}\\n')\n",
        "\n",
        "# hyperparamters tuning\n",
        "best_k = None\n",
        "best_metric = None\n",
        "best_score = 0\n",
        "for k in [5, 15, 25, 35, 45, 55, 65, 75, 85, 95, 500]:\n",
        "    for metric in ['euclidean', 'manhattan']:\n",
        "      print(f'Evaluating k={k} and metric={metric}...')\n",
        "      knn = KNN(k=k, distance_metric=metric)\n",
        "      cv_score = np.mean(cross_validate(X, y, knn))\n",
        "      print(f'Cross-validation score for k={k} and metric={metric}: {cv_score:.6f}\\n')\n",
        "\n",
        "      if cv_score > best_score:\n",
        "          best_score = cv_score\n",
        "          best_k = k\n",
        "          best_metric = metric\n",
        "\n",
        "print(f'Best k: {best_k} and metric: {best_metric} with score: {best_score}')\n",
        "\n",
        "# train on full dataset with optimal hyperparameters and make predictions on test set\n",
        "knn = KNN(k=45, distance_metric='euclidean')\n",
        "knn.fit(X, y)\n",
        "test_predictions = knn.predict(X_test)\n",
        "\n",
        "# Save test predictions\n",
        "ans = pd.DataFrame({'id': pd.read_csv('/content/test.csv')['id'], 'Exited': test_predictions}).to_csv('/content/submissions.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "cs506",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.15"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}